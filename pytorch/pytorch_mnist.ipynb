{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Pytorch\n",
    "\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = '/tmp/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv(TRAIN_DATA, nrows=5)\n",
    "tmp = tmp.loc[:, tmp.columns != 'label']\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n",
    "\n",
    "* `__len__` so that `len(dataset)` returns the size of the dataset.\n",
    "* `__getitem__` to support the indexing such that `dataset[i]` can be used to get ith sample\n",
    "\n",
    "The data must be wrapped in a Dataset class. First the data must be wrapped in a Dataset class with a `getitem` method that from an index return `X_train[index]` and `y_train[index]` and a length method. A Dataset is basically a data storage. We will read the csv in `__init__` but leave the reading of images to `__getitem__`. This is memory efficient because all the images are not stored in the memory at once but read as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        df = pd.read_csv(csv_file).astype(np.float32)\n",
    "        self.enc = OneHotEncoder()\n",
    "        self.X_train = df.loc[:, df.columns != 'label'].as_matrix()\n",
    "        self.y_train = self.enc.fit_transform(df['label'].values.reshape(-1, 1)).toarray()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.from_numpy(self.X_train[index])\n",
    "        label = torch.Tensor(self.y_train[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = MNISTDataset(csv_file = TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xbb45f60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dset_train[0][1])\n",
    "plt.imshow(dset_train[0][0].view(28, 28).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loader = DataLoader(dset_train, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/42000 (0%)]\tLoss: 7.380072\n",
      "Train Epoch: 0 [2560/42000 (6%)]\tLoss: 1.451335\n",
      "Train Epoch: 0 [5120/42000 (12%)]\tLoss: 1.133739\n",
      "Train Epoch: 0 [7680/42000 (18%)]\tLoss: 0.664101\n",
      "Train Epoch: 0 [10240/42000 (24%)]\tLoss: 0.664842\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.665082\n",
      "Train Epoch: 0 [15360/42000 (36%)]\tLoss: 0.530678\n",
      "Train Epoch: 0 [17920/42000 (42%)]\tLoss: 0.507366\n",
      "Train Epoch: 0 [20480/42000 (48%)]\tLoss: 0.365820\n",
      "Train Epoch: 0 [23040/42000 (55%)]\tLoss: 0.396803\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.317529\n",
      "Train Epoch: 0 [28160/42000 (67%)]\tLoss: 0.367664\n",
      "Train Epoch: 0 [30720/42000 (73%)]\tLoss: 0.280107\n",
      "Train Epoch: 0 [33280/42000 (79%)]\tLoss: 0.370477\n",
      "Train Epoch: 0 [35840/42000 (85%)]\tLoss: 0.245904\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.301574\n",
      "Train Epoch: 0 [40960/42000 (97%)]\tLoss: 0.229639\n",
      "Train Epoch: 1 [0/42000 (0%)]\tLoss: 0.282863\n",
      "Train Epoch: 1 [2560/42000 (6%)]\tLoss: 0.283320\n",
      "Train Epoch: 1 [5120/42000 (12%)]\tLoss: 0.301545\n",
      "Train Epoch: 1 [7680/42000 (18%)]\tLoss: 0.228608\n",
      "Train Epoch: 1 [10240/42000 (24%)]\tLoss: 0.239351\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.248813\n",
      "Train Epoch: 1 [15360/42000 (36%)]\tLoss: 0.237327\n",
      "Train Epoch: 1 [17920/42000 (42%)]\tLoss: 0.233894\n",
      "Train Epoch: 1 [20480/42000 (48%)]\tLoss: 0.179628\n",
      "Train Epoch: 1 [23040/42000 (55%)]\tLoss: 0.192437\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.232984\n",
      "Train Epoch: 1 [28160/42000 (67%)]\tLoss: 0.185583\n",
      "Train Epoch: 1 [30720/42000 (73%)]\tLoss: 0.203985\n",
      "Train Epoch: 1 [33280/42000 (79%)]\tLoss: 0.211471\n",
      "Train Epoch: 1 [35840/42000 (85%)]\tLoss: 0.205152\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.197517\n",
      "Train Epoch: 1 [40960/42000 (97%)]\tLoss: 0.236960\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "#criterion = nn.MultiLabelSoftMarginLoss()\n",
    "criterion = nn.BCELoss()\n",
    "#criterion = F.binary_cross_entropy\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.001)\n",
    "                      \n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    mlp.train()\n",
    "    for batch_idx, (data, target) in enumerate(dset_loader):\n",
    "        # get the inputs\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        output = mlp(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                batch_idx * len(data), \n",
    "                len(dset_loader.dataset),\n",
    "                100. * batch_idx / len(dset_loader), \n",
    "                loss.data.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0724e-09,  9.9995e-01,  2.8310e-02,  5.1610e-07,  4.9424e-07,\n",
       "         6.8401e-08,  2.6044e-09,  5.2415e-03,  6.1218e-02,  9.1099e-06])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dset_train[0][1])\n",
    "mlp(dset_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = MNISTDataset(csv_file = TRAIN_DATA, transform = (lambda x: x.view(1, 28, 28)))\n",
    "dset_loader = DataLoader(dset_train, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/42000 (0%)]\tLoss: 6.050994\n",
      "Train Epoch: 0 [2560/42000 (6%)]\tLoss: 0.484892\n",
      "Train Epoch: 0 [5120/42000 (12%)]\tLoss: 0.275754\n",
      "Train Epoch: 0 [7680/42000 (18%)]\tLoss: 0.229722\n",
      "Train Epoch: 0 [10240/42000 (24%)]\tLoss: 0.186822\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.145604\n",
      "Train Epoch: 0 [15360/42000 (36%)]\tLoss: 0.123394\n",
      "Train Epoch: 0 [17920/42000 (42%)]\tLoss: 0.111459\n",
      "Train Epoch: 0 [20480/42000 (48%)]\tLoss: 0.085979\n",
      "Train Epoch: 0 [23040/42000 (55%)]\tLoss: 0.099859\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.061109\n",
      "Train Epoch: 0 [28160/42000 (67%)]\tLoss: 0.067298\n",
      "Train Epoch: 0 [30720/42000 (73%)]\tLoss: 0.063181\n",
      "Train Epoch: 0 [33280/42000 (79%)]\tLoss: 0.063011\n",
      "Train Epoch: 0 [35840/42000 (85%)]\tLoss: 0.048802\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.052184\n",
      "Train Epoch: 0 [40960/42000 (97%)]\tLoss: 0.052897\n",
      "Train Epoch: 1 [0/42000 (0%)]\tLoss: 0.069507\n",
      "Train Epoch: 1 [2560/42000 (6%)]\tLoss: 0.049335\n",
      "Train Epoch: 1 [5120/42000 (12%)]\tLoss: 0.040764\n",
      "Train Epoch: 1 [7680/42000 (18%)]\tLoss: 0.047997\n",
      "Train Epoch: 1 [10240/42000 (24%)]\tLoss: 0.034879\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.041080\n",
      "Train Epoch: 1 [15360/42000 (36%)]\tLoss: 0.036122\n",
      "Train Epoch: 1 [17920/42000 (42%)]\tLoss: 0.038512\n",
      "Train Epoch: 1 [20480/42000 (48%)]\tLoss: 0.030443\n",
      "Train Epoch: 1 [23040/42000 (55%)]\tLoss: 0.028467\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.040301\n",
      "Train Epoch: 1 [28160/42000 (67%)]\tLoss: 0.037717\n",
      "Train Epoch: 1 [30720/42000 (73%)]\tLoss: 0.032913\n",
      "Train Epoch: 1 [33280/42000 (79%)]\tLoss: 0.022707\n",
      "Train Epoch: 1 [35840/42000 (85%)]\tLoss: 0.033679\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.030834\n",
      "Train Epoch: 1 [40960/42000 (97%)]\tLoss: 0.032222\n"
     ]
    }
   ],
   "source": [
    "conv_net = ConvNet()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(conv_net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    conv_net.train()\n",
    "    for batch_idx, (data, target) in enumerate(dset_loader):\n",
    "        # get the inputs\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        output = conv_net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                batch_idx * len(data), \n",
    "                len(dset_loader.dataset),\n",
    "                100. * batch_idx / len(dset_loader), \n",
    "                loss.data.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
